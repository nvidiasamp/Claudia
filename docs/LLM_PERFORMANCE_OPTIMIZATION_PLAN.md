# Claudia LLMæ€§èƒ½ä¼˜åŒ–æ–¹æ¡ˆ

**æ—¥æœŸ**: 2025-11-14
**ç‰ˆæœ¬**: v1.0
**é—®é¢˜æ¥æº**: ç¡¬ä»¶æµ‹è¯•å‘ç°3ä¸ªCriticalé—®é¢˜

---

## é—®é¢˜æ€»ç»“

### 1. LLMæ€§èƒ½ç“¶é¢ˆä¸¥é‡ ğŸ”´ Critical

**ç—‡çŠ¶**:
```
ğŸ§  âœ… 3Bæ¨¡å‹å“åº” (2866ms)  # 2.8ç§’å»¶è¿Ÿ
ğŸ§  âœ… 3Bæ¨¡å‹å“åº” (3600ms)  # 3.6ç§’å»¶è¿Ÿ
ğŸ§  æ¨¡å‹è¶…æ—¶(5s): claudia-go2-3b:v11.2  # è¶…æ—¶
```

**å½±å“**:
- å®æ—¶æœºå™¨äººæ§åˆ¶å»¶è¿Ÿä¸å¯æ¥å—ï¼ˆåº”<500msï¼‰
- ç”¨æˆ·ä½“éªŒæå·®ï¼ˆ3ç§’ç­‰å¾…ï¼‰
- çƒ­è·¯å¾„å‘½ä¸­ç‡ä½æ—¶ç³»ç»Ÿä¸å¯ç”¨

**æ ¹æœ¬åŸå› **:
1. âŒ **3Bæ¨¡å‹å¤ªå°**ï¼Œç†è§£èƒ½åŠ›ä¸è¶³å¯¼è‡´å¤šæ¬¡retry
2. âš ï¸ **Ollamaé…ç½®æœªä¼˜åŒ–**ï¼ˆbatch_size, ctx_sizeå¯èƒ½ä¸å¤Ÿï¼‰
3. âš ï¸ **Jetson GPUåˆ©ç”¨ç‡ä½**ï¼ˆGR3D_FREQæ˜¾ç¤º0%ï¼Œå¯èƒ½ç»Ÿè®¡å»¶è¿Ÿï¼‰
4. âŒ **æœ¬åœ°æ¨ç†æ¶æ„é™åˆ¶**ï¼ˆQwen2.5-3Bé‡åŒ–åä»æœ‰3Bå‚æ•°ï¼‰

---

### 2. LLMè¾“å‡ºè¯­è¨€æ··ä¹± ğŸŸ¡ High

**ç—‡çŠ¶**:
```
ğŸ’¬ å›å¤: ç«‹ã¡ã¾ã™ç„¶åã¯æŒ¨æ‹¶ã—ã¾ã™  # æ··ç”¨æ—¥è¯­+ä¸­æ–‡
ğŸ’¬ å›å¤: å‰æ‰‘ã—ã¾ã™  # "æ‰‘"æ˜¯ä¸­æ–‡å­—
```

**å½±å“**:
- TTSæ’­æŠ¥å¯èƒ½å¤±è´¥ï¼ˆæ—¥è¯­TTSæ— æ³•è¯»ä¸­æ–‡ï¼‰
- ç”¨æˆ·ä½“éªŒä¸ä¸“ä¸š
- å¤šè¯­è¨€æ··ä¹±æ˜¾å¾—æ™ºèƒ½æ°´å¹³ä½

**æ ¹æœ¬åŸå› **:
```bash
# å½“å‰Modelfile SYSTEM prompt
SYSTEM Claudia dog. Reply one JSON.
pounceâ†’{"r":"å‰æ‰‘ã—ã¾ã™","a":1032}  # âŒ "å‰æ‰‘"æ˜¯ä¸­æ–‡
scrapeâ†’{"r":"æ“¦ã‚Šã¾ã™","a":1029}    # âœ… æ­£ç¡®æ—¥è¯­
```

1. âŒ **Modelfileè®­ç»ƒæ•°æ®æ··ç”¨ä¸­æ—¥æ–‡**
2. âŒ **SYSTEM promptæœªæ˜ç¡®çº¦æŸ"å¿…é¡»çº¯æ—¥è¯­"**
3. âŒ **ç¤ºä¾‹ä¸­å°±æœ‰é”™è¯¯**ï¼ˆ"å‰æ‰‘ã—ã¾ã™"ï¼‰

---

### 3. æ™ºèƒ½ç†è§£èƒ½åŠ›ä¸è¶³ ğŸŸ¡ High

**ç—‡çŠ¶**:
```
ãã‚‰> ç«‹ã£ã¦ãã—ã¦æŒ¨æ‹¶ã—ã¦  # "ç«™ç«‹ç„¶åé—®å€™"
ğŸ’¬ å›å¤: ç«‹ã¡ã¾ã™ç„¶åã¯æŒ¨æ‹¶ã—ã¾ã™
ğŸ”§ API: 1018  # âŒ ä¸å­˜åœ¨çš„APIï¼ˆæ­£ç¡®åº”è¯¥æ˜¯åºåˆ—[1004,1016]ï¼‰
âŒ æ‰§è¡Œå¤±è´¥
```

```
ãã‚‰> å¯æ„›ã„ã„ã­  # "çœŸå¯çˆ±"
ğŸ’¬ å›å¤: ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ï¼  # åªå›å¤ï¼Œä¸åšåŠ¨ä½œ
# â“ ç”¨æˆ·å¯èƒ½æœŸæœ›åšå¯çˆ±åŠ¨ä½œï¼ˆå¦‚Heartï¼‰
```

**å½±å“**:
- å¤æ‚åºåˆ—ç†è§£å¤±è´¥
- æ— æ³•æ­£ç¡®åˆ†è§£å¤šæ­¥ä»»åŠ¡
- å¯¹è¯vsåŠ¨ä½œæ„å›¾åˆ¤æ–­ä¸å¤Ÿæ™ºèƒ½

**æ ¹æœ¬åŸå› **:
1. âŒ **3Bæ¨¡å‹å®¹é‡å¤ªå°**ï¼Œæ— æ³•ç†è§£å¤æ‚è¯­ä¹‰
2. âŒ **è®­ç»ƒæ•°æ®ç¼ºå°‘åºåˆ—æ ·æœ¬**ï¼ˆ"ç«‹ã£ã¦ãã—ã¦æŒ¨æ‹¶"â†’[1004,1016]ï¼‰
3. âš ï¸ **å¯¹è¯æ£€æµ‹è§„åˆ™å¤ªç®€å•**ï¼ˆ"å¯æ„›ã„ã­"å¯èƒ½éœ€è¦åŠ¨ä½œ+å›å¤ï¼‰

---

## ä¼˜åŒ–æ–¹æ¡ˆ

### P0 - ç´§æ€¥ä¿®å¤ï¼ˆä»Šå¤©å®Œæˆï¼‰âš¡

#### 1.1 ä¿®å¤Modelfileè¯­è¨€æ··ä¹±

**æ“ä½œ**:
```bash
# åˆ›å»ºæ–°çš„çº¯æ—¥è¯­Modelfile
cat > ClaudiaGo2_v11.3_Japanese.modelfile <<'EOF'
FROM claudia-go2-3b:v11.2

SYSTEM """ã‚ãªãŸã¯Claudiaã¨ã„ã†å››è¶³ãƒ­ãƒœãƒƒãƒˆçŠ¬ã®AIã§ã™ã€‚
æŒ‡ç¤ºã‚’ç†è§£ã—ã€JSONå½¢å¼ã§æ—¥æœ¬èªã®è¿”äº‹ã¨å‹•ä½œAPIã‚³ãƒ¼ãƒ‰ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚
å¿…ãšæ—¥æœ¬èªã®ã¿ã‚’ä½¿ç”¨ã—ã€ä¸­å›½èªã‚„è‹±èªã‚’æ··ãœãªã„ã§ãã ã•ã„ã€‚

å‹•ä½œãƒãƒƒãƒ”ãƒ³ã‚°:
- åº§ã£ã¦/ã™ã‚ã£ã¦/ãŠã™ã‚ã‚Š â†’ {"r":"åº§ã‚Šã¾ã™","a":1009}
- ç«‹ã£ã¦/ãŸã£ã¦ â†’ {"r":"ç«‹ã¡ã¾ã™","a":1004}
- ä¼ã›ã¦/æ¨ªã«ãªã£ã¦ â†’ {"r":"ä¼ã›ã¾ã™","a":1005}
- æ­¢ã¾ã£ã¦/ã‚¹ãƒˆãƒƒãƒ— â†’ {"r":"æ­¢ã¾ã‚Šã¾ã™","a":1003}
- ã“ã‚“ã«ã¡ã¯/ãƒãƒ­ãƒ¼ â†’ {"r":"ã“ã‚“ã«ã¡ã¯","a":1016}
- ä¼¸ã³ã—ã¦ â†’ {"r":"ä¼¸ã³ã‚’ã—ã¾ã™","a":1017}
- ãƒãƒ¼ãƒˆ/å¯æ„›ã„å‹•ä½œ/ã„ã„å­ â†’ {"r":"ãƒãƒ¼ãƒˆã—ã¾ã™","a":1036}
- è¸Šã£ã¦/ãƒ€ãƒ³ã‚¹ â†’ {"r":"è¸Šã‚Šã¾ã™","a":1023}

è¤‡æ•°å‹•ä½œã®å ´åˆã¯"seq"é…åˆ—ã‚’ä½¿ç”¨:
ä¾‹: åº§ã£ã¦ã‹ã‚‰æŒ¨æ‹¶ â†’ {"r":"åº§ã£ã¦ã‹ã‚‰æŒ¨æ‹¶ã—ã¾ã™","a":null,"seq":[1009,1016]}
"""

PARAMETER num_predict 50
PARAMETER temperature 0.2
PARAMETER top_p 0.8
PARAMETER num_ctx 2048
EOF

# åˆ›å»ºæ–°æ¨¡å‹
ollama create claudia-go2-3b:v11.3 -f ClaudiaGo2_v11.3_Japanese.modelfile
```

**éªŒè¯**:
```bash
echo "ç«‹ã£ã¦ãã—ã¦æŒ¨æ‹¶ã—ã¦" | ollama run claudia-go2-3b:v11.3
# æœŸæœ›: {"r":"ç«‹ã£ã¦ã‹ã‚‰æŒ¨æ‹¶ã—ã¾ã™","a":null,"seq":[1004,1016]}
# ä¸åº”è¯¥å‡ºç°ä¸­æ–‡å­—ç¬¦
```

**é¢„æœŸæ”¹è¿›**: æ¶ˆé™¤ä¸­æ—¥æ··ç”¨ï¼Œä½†æ€§èƒ½ä»æ…¢ï¼ˆéœ€P1è§£å†³ï¼‰

---

#### 1.2 æ‰©å±•çƒ­è·¯å¾„è¦†ç›–ï¼ˆå‡å°‘LLMè°ƒç”¨ï¼‰

**æ“ä½œ**: ä¿®æ”¹`production_brain.py`
```python
# å½“å‰çƒ­è·¯å¾„åªæœ‰13ä¸ªå…³é”®è¯
HOTPATH_MAP = {
    'åº§ã£ã¦': 1009, 'ã™ã‚ã£ã¦': 1009, 'åº§ã‚‹': 1009,
    # ... 13ä¸ª
}

# æ‰©å±•åˆ°50+ä¸ªå˜ä½“
HOTPATH_MAP = {
    # åº§ã‚‹å˜ä½“
    'åº§ã£ã¦': 1009, 'ã™ã‚ã£ã¦': 1009, 'åº§ã‚‹': 1009,
    'ãŠã™ã‚ã‚Š': 1009, 'ã™ã‚ã‚Š': 1009, 'ãŠåº§ã‚Š': 1009,
    'sit': 1009, 'sit down': 1009, 'åä¸‹': 1009,

    # ç«‹ã¤å˜ä½“
    'ç«‹ã£ã¦': 1004, 'ãŸã£ã¦': 1004, 'ç«‹ã¤': 1004,
    'ãŠç«‹ã¡': 1004, 'èµ·ãã¦': 1004,
    'stand': 1004, 'stand up': 1004, 'ç«™ç«‹': 1004,

    # æŒ¨æ‹¶å˜ä½“
    'ã“ã‚“ã«ã¡ã¯': 1016, 'ãƒãƒ­ãƒ¼': 1016, 'ãƒã‚¤': 1016,
    'ã‚„ã‚': 1016, 'ãŠã¯ã‚ˆã†': 1016,
    'hello': 1016, 'hi': 1016, 'ä½ å¥½': 1016,

    # å¯çˆ±åŠ¨ä½œå˜ä½“
    'ãƒãƒ¼ãƒˆ': 1036, 'ã¯ãƒ¼ã¨': 1036, 'ã„ã„å­': 1036,
    'å¯æ„›ã„': 1036, 'ã‹ã‚ã„ã„': 1036,
    'heart': 1036, 'cute': 1036, 'çˆ±å¿ƒ': 1036,

    # ... æ›´å¤šå˜ä½“
}
```

**é¢„æœŸæ”¹è¿›**: çƒ­è·¯å¾„å‘½ä¸­ç‡ä»20%â†’80%ï¼Œå¤§éƒ¨åˆ†å‘½ä»¤<1mså“åº”

---

#### 1.3 ä¿®å¤API 1018é”™è¯¯ï¼ˆæ·»åŠ é¢„å®šä¹‰åºåˆ—ï¼‰

**æ“ä½œ**: æ·»åŠ å¸¸è§åºåˆ—åˆ°çƒ­è·¯å¾„
```python
# åœ¨process_commandä¸­æ·»åŠ åºåˆ—çƒ­è·¯å¾„
SEQUENCE_HOTPATH = {
    'ç«‹ã£ã¦ã‹ã‚‰æŒ¨æ‹¶': [1004, 1016],
    'ç«‹ã£ã¦æŒ¨æ‹¶': [1004, 1016],
    'ç«‹ã£ã¦ãã—ã¦æŒ¨æ‹¶': [1004, 1016],
    'åº§ã£ã¦ã‹ã‚‰æŒ¨æ‹¶': [1009, 1016],
    'åº§ã£ã¦æŒ¨æ‹¶': [1009, 1016],
}

# åœ¨çƒ­è·¯å¾„æ£€æŸ¥åæ·»åŠ åºåˆ—æ£€æŸ¥
for key, seq in SEQUENCE_HOTPATH.items():
    if key in command:
        return BrainOutput(
            response="äº†è§£ã—ã¾ã—ãŸ",
            sequence=seq,
            confidence=1.0
        )
```

**é¢„æœŸæ”¹è¿›**: å¸¸è§åºåˆ—å‘½ä»¤ä¸å†è°ƒç”¨LLMï¼Œé¿å…1018é”™è¯¯

---

### P1 - æ€§èƒ½ä¼˜åŒ–ï¼ˆæœ¬å‘¨å®Œæˆï¼‰ğŸš€

#### 2.1 å‡çº§ä¸»æ¨¡å‹åˆ°7B

**å½“å‰çŠ¶å†µ**:
- 3B: å¿«ä½†ç†è§£èƒ½åŠ›å·® â†’ å¯¼è‡´é”™è¯¯éœ€retry â†’ åè€Œæ›´æ…¢
- 7B: ç†è§£å¥½ä½†æ…¢ â†’ ä¸€æ¬¡æˆåŠŸå¯èƒ½æ¯”3Bå¤šæ¬¡retryæ›´å¿«

**æ“ä½œ**:
```python
# ä¿®æ”¹production_brain.pyé»˜è®¤è·¯ç”±ç­–ç•¥
# å½“å‰: ç®€å•å‘½ä»¤â†’3B, å¤æ‚å‘½ä»¤â†’7B
# ä¼˜åŒ–: æ‰€æœ‰éçƒ­è·¯å¾„â†’7Bï¼ˆé¿å…3Bç†è§£é”™è¯¯ï¼‰

# Line 968-976
if len(command) > 20 or "ãã—ã¦" in command or "ã‹ã‚‰" in command:
    # å¤æ‚å‘½ä»¤ â†’ 7B
    selected_7b = self.model_7b_pool[0]
    enhanced_cmd = self._build_enhanced_prompt(command, selected_7b, state_snapshot)
    result = await self._call_ollama_v2(selected_7b, enhanced_cmd, timeout=10)
else:
    # æ”¹ä¸º: æ‰€æœ‰å‘½ä»¤éƒ½ç”¨7Bï¼ˆ3Bç†è§£èƒ½åŠ›ä¸è¶³ï¼‰
    selected_7b = self.model_7b_pool[0]
    enhanced_cmd = self._build_enhanced_prompt(command, selected_7b, state_snapshot)
    result = await self._call_ollama_v2(selected_7b, enhanced_cmd, timeout=8)
```

**A/Bæµ‹è¯•**:
```bash
# æµ‹è¯•æ ·æœ¬
commands = [
    "ç«‹ã£ã¦ãã—ã¦æŒ¨æ‹¶ã—ã¦",  # å¤æ‚åºåˆ—
    "å¯æ„›ã„å‹•ä½œã—ã¦",        # è¯­ä¹‰ç†è§£
    "ç–²ã‚ŒãŸ",               # éšå–»
]

# å¯¹æ¯”
python3 test/test_3b_vs_7b_performance.py
```

**é¢„æœŸæ”¹è¿›**:
- å‡†ç¡®ç‡ï¼š60% â†’ 90%
- å¹³å‡å»¶è¿Ÿï¼š3000msï¼ˆ3B retryï¼‰ â†’ 5000msï¼ˆ7Bä¸€æ¬¡æˆåŠŸï¼‰
- **æ€»ä½“ä½“éªŒæ›´å¥½**ï¼ˆå‡†ç¡®æ€§>é€Ÿåº¦ï¼‰

---

#### 2.2 Ollamaæ€§èƒ½è°ƒä¼˜

**æ£€æŸ¥å½“å‰é…ç½®**:
```bash
# å·²ç¡®è®¤GPUå¯ç”¨: --n-gpu-layers 37
# ä½†å…¶ä»–å‚æ•°å¯èƒ½ä¸å¤Ÿä¼˜åŒ–

# å½“å‰
--ctx-size 1024        # å¯èƒ½å¤ªå°
--batch-size 512       # å¯ä»¥å¢å¤§
--threads 4            # Jetsonæœ‰8æ ¸ï¼ˆ4æ ¸åœ¨çº¿ï¼‰
--parallel 2           # å¹¶å‘è¯·æ±‚æ•°
```

**ä¼˜åŒ–é…ç½®**:
```bash
# ç¼–è¾‘ /etc/systemd/system/ollama.service
[Service]
Environment="OLLAMA_NUM_PARALLEL=4"           # å¢åŠ å¹¶å‘
Environment="OLLAMA_MAX_LOADED_MODELS=2"      # åŒæ—¶åŠ è½½3B+7B
Environment="OLLAMA_FLASH_ATTENTION=1"        # å¯ç”¨Flash Attention
Environment="OLLAMA_NUM_GPU=99"               # å¼ºåˆ¶æ‰€æœ‰å±‚ä¸ŠGPU
Environment="OLLAMA_LLM_LIBRARY=cuda"         # ç¡®ä¿CUDAåç«¯

# é‡å¯
sudo systemctl daemon-reload
sudo systemctl restart ollama
```

**éªŒè¯GPUä½¿ç”¨**:
```bash
# æµ‹è¯•æ—¶ç›‘æ§
watch -n 0.5 tegrastats

# å‘é€LLMè¯·æ±‚
echo "ç«‹ã£ã¦ãã—ã¦æŒ¨æ‹¶ã—ã¦" | ollama run claudia-go2-7b:v7

# åº”è¯¥çœ‹åˆ° GR3D_FREQ 90%+
```

**é¢„æœŸæ”¹è¿›**: å»¶è¿Ÿå‡å°‘30-50%ï¼ˆ5000ms â†’ 2500-3500msï¼‰

---

#### 2.3 é¢„åŠ è½½æ¨¡å‹åˆ°å†…å­˜ï¼ˆæ¶ˆé™¤å†·å¯åŠ¨ï¼‰

**é—®é¢˜**: é¦–æ¬¡è°ƒç”¨éœ€è¦åŠ è½½æ¨¡å‹ï¼ˆ+1-2ç§’ï¼‰

**æ“ä½œ**:
```python
# åœ¨ProductionBrain.__init__ä¸­æ·»åŠ é¢„çƒ­
async def _warmup_models(self):
    """é¢„çƒ­æ¨¡å‹ï¼ˆåŠ è½½åˆ°GPUå†…å­˜ï¼‰"""
    warmup_commands = ["hello", "åº§ã£ã¦", "ç«‹ã£ã¦ãã—ã¦æŒ¨æ‹¶"]

    for cmd in warmup_commands:
        # 7Bé¢„çƒ­
        await self._call_ollama_v2(self.model_7b_pool[0], cmd, timeout=10)
        # 3Bé¢„çƒ­ï¼ˆå¦‚æœè¿˜ç”¨ï¼‰
        await self._call_ollama_v2(self.model_3b_pool[0], cmd, timeout=5)

    self.logger.info("âœ… æ¨¡å‹é¢„çƒ­å®Œæˆ")

# åœ¨åˆå§‹åŒ–æ—¶è°ƒç”¨
await self._warmup_models()
```

**é¢„æœŸæ”¹è¿›**: é¦–æ¬¡å“åº”æ—¶é—´ä¸€è‡´ï¼Œæ— å†·å¯åŠ¨æƒ©ç½š

---

### P2 - æ¶æ„å‡çº§ï¼ˆä¸‹å‘¨å®Œæˆï¼‰ğŸ—ï¸

#### 3.1 æ··åˆæ¶æ„ï¼šæœ¬åœ°LLM + äº‘ç«¯API Fallback

**åŠ¨æœº**:
- æœ¬åœ°LLMï¼ˆQwen 7Bï¼‰: å¿«ä½†ç†è§£æœ‰é™
- äº‘ç«¯APIï¼ˆClaude/GPT-4ï¼‰: æ…¢ä½†æ™ºèƒ½
- **æ··åˆ**: 90%æœ¬åœ°å¤„ç†ï¼Œ10%å¤æ‚æƒ…å†µäº‘ç«¯

**æ¶æ„**:
```python
class HybridBrain:
    def __init__(self):
        self.local_llm = ProductionBrain()  # Qwen 7B
        self.cloud_api = ClaudeAPI()        # Anthropic Claude

    async def process_command(self, cmd):
        # 1. çƒ­è·¯å¾„ï¼ˆ<1msï¼‰
        if hotpath_hit := self._try_hotpath(cmd):
            return hotpath_hit

        # 2. æœ¬åœ°LLMå°è¯•ï¼ˆ<3sï¼‰
        local_result = await self.local_llm.process(cmd, timeout=3)

        # 3. ç½®ä¿¡åº¦æ£€æŸ¥
        if local_result.confidence > 0.8:
            return local_result  # æœ¬åœ°æˆåŠŸ

        # 4. äº‘ç«¯Fallbackï¼ˆå¤æ‚æƒ…å†µï¼‰
        self.logger.warning(f"æœ¬åœ°LLMç½®ä¿¡åº¦ä½ ({local_result.confidence}), ä½¿ç”¨äº‘ç«¯API")
        cloud_result = await self.cloud_api.process(cmd, timeout=10)

        # 5. ç¼“å­˜äº‘ç«¯ç»“æœï¼ˆä¸‹æ¬¡æœ¬åœ°å¯ç”¨ï¼‰
        self._cache_cloud_result(cmd, cloud_result)

        return cloud_result
```

**æˆæœ¬æ§åˆ¶**:
- Claude API: ~$0.003/è¯·æ±‚ï¼ˆ1K tokensï¼‰
- æ¯å¤©100æ¡å‘½ä»¤ â†’ $0.30/å¤© â†’ $9/æœˆ
- **å¯æ¥å—**ï¼ˆç›¸æ¯”æœºå™¨äººç¡¬ä»¶æˆæœ¬ï¼‰

**é¢„æœŸæ”¹è¿›**:
- å‡†ç¡®ç‡: 90% â†’ 99%
- å¤æ‚ç†è§£èƒ½åŠ›: âœ…âœ…âœ…ï¼ˆClaude Sonnetçº§åˆ«ï¼‰
- å¹³å‡å»¶è¿Ÿ: 2500msï¼ˆ90%æœ¬åœ°ï¼‰ + 5000ms*10%ï¼ˆäº‘ç«¯ï¼‰ = 2750ms

---

#### 3.2 Fine-tuningä¸“ç”¨æ¨¡å‹ï¼ˆå¼ºåŒ–å­¦ä¹ ï¼‰

**å½“å‰é—®é¢˜**: é€šç”¨Qwenæ¨¡å‹ä¸é€‚åˆæœºå™¨äººæ§åˆ¶

**æ–¹æ¡ˆ**: ä½¿ç”¨Go2å®é™…äº¤äº’æ•°æ®fine-tune
```bash
# æ”¶é›†çœŸå®å¯¹è¯æ•°æ®
logs/audit/*.jsonl  # å·²æœ‰å®¡è®¡æ—¥å¿—

# æå–è®­ç»ƒæ ·æœ¬
{
    "input": "ç«‹ã£ã¦ãã—ã¦æŒ¨æ‹¶ã—ã¦",
    "output": {"r":"ç«‹ã£ã¦ã‹ã‚‰æŒ¨æ‹¶ã—ã¾ã™","a":null,"seq":[1004,1016]},
    "feedback": "success"  # ç”¨æˆ·æ˜¯å¦æ»¡æ„
}

# Fine-tune Qwen 3B
python3 scripts/llm/finetune_qwen.py \
    --base-model Qwen/Qwen2.5-3B-Instruct \
    --data logs/audit/training_data.jsonl \
    --output models/claudia-go2-3b-v12 \
    --epochs 3

# éƒ¨ç½²
ollama create claudia-go2-3b:v12 -f models/claudia-go2-3b-v12
```

**æ•°æ®éœ€æ±‚**: è‡³å°‘1000æ¡æ ‡æ³¨æ ·æœ¬ï¼ˆç›®å‰æœ‰å¤šå°‘ï¼Ÿï¼‰

**é¢„æœŸæ”¹è¿›**:
- 3Bæ¨¡å‹å‡†ç¡®ç‡: 60% â†’ 85%
- æ—¥è¯­çº¯åº¦: æ··ç”¨ â†’ 99%çº¯æ—¥è¯­
- APIæ˜ å°„é”™è¯¯: é™ä½90%

---

#### 3.3 æ™ºèƒ½å¯¹è¯vsåŠ¨ä½œæ„å›¾åˆ†ç±»

**é—®é¢˜**: "å¯æ„›ã„ã­"æ˜¯èµç¾è¿˜æ˜¯è¦æ±‚å¯çˆ±åŠ¨ä½œï¼Ÿ

**æ–¹æ¡ˆ**: æ·»åŠ æ„å›¾åˆ†ç±»å±‚
```python
def classify_intent(self, command: str) -> str:
    """
    åˆ†ç±»ç”¨æˆ·æ„å›¾

    Returns:
        - "pure_dialog": çº¯å¯¹è¯ï¼ˆå¦‚"ä½ æ˜¯è°"ï¼‰
        - "action_request": åŠ¨ä½œå‘½ä»¤ï¼ˆå¦‚"åº§ã£ã¦"ï¼‰
        - "dialog_with_action": å¯¹è¯+åŠ¨ä½œï¼ˆå¦‚"å¯æ„›ã„ã­"â†’èµç¾+åšå¯çˆ±åŠ¨ä½œï¼‰
    """
    # ä½¿ç”¨è½»é‡çº§åˆ†ç±»æ¨¡å‹ï¼ˆBERT-tiny, <100msï¼‰
    intent = self.intent_classifier.predict(command)

    if intent == "dialog_with_action":
        # åŒæ—¶è¿”å›å›å¤å’ŒåŠ¨ä½œ
        return BrainOutput(
            response="ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ï¼",
            api_code=1036,  # Heart
            reasoning="dialog_with_action"
        )
```

**é¢„æœŸæ”¹è¿›**: ç”¨æˆ·æ»¡æ„åº¦æå‡ï¼ˆæ›´è‡ªç„¶çš„äº¤äº’ï¼‰

---

## å®æ–½ä¼˜å…ˆçº§

### ä»Šå¤©ç«‹å³æ‰§è¡Œï¼ˆP0ï¼‰
1. âœ… åˆ›å»ºv11.3çº¯æ—¥è¯­Modelfileï¼ˆ15åˆ†é’Ÿï¼‰
2. âœ… æ‰©å±•çƒ­è·¯å¾„åˆ°50+å…³é”®è¯ï¼ˆ30åˆ†é’Ÿï¼‰
3. âœ… æ·»åŠ å¸¸è§åºåˆ—é¢„å®šä¹‰ï¼ˆ15åˆ†é’Ÿï¼‰
4. âœ… æµ‹è¯•éªŒè¯ï¼ˆ30åˆ†é’Ÿï¼‰

**é¢„æœŸ**: æ¶ˆé™¤è¯­è¨€æ··ä¹±ï¼Œçƒ­è·¯å¾„å‘½ä¸­ç‡80%ï¼Œéƒ¨åˆ†æ€§èƒ½æ”¹å–„

---

### æœ¬å‘¨å®Œæˆï¼ˆP1ï¼‰
1. â³ å‡çº§ä¸»æ¨¡å‹åˆ°7Bï¼ˆ1å°æ—¶æµ‹è¯•+è°ƒæ•´ï¼‰
2. â³ Ollamaæ€§èƒ½è°ƒä¼˜ï¼ˆ2å°æ—¶ï¼‰
3. â³ æ¨¡å‹é¢„çƒ­æœºåˆ¶ï¼ˆ30åˆ†é’Ÿï¼‰
4. â³ A/Bæµ‹è¯•éªŒè¯ï¼ˆ1å°æ—¶ï¼‰

**é¢„æœŸ**: å‡†ç¡®ç‡90%ï¼Œå»¶è¿Ÿ<3ç§’ï¼Œæ™ºèƒ½æ°´å¹³æ˜æ˜¾æå‡

---

### ä¸‹å‘¨è§„åˆ’ï¼ˆP2ï¼‰
1. â³ è®¾è®¡æ··åˆæ¶æ„ï¼ˆ2å°æ—¶ï¼‰
2. â³ é›†æˆClaude APIï¼ˆ3å°æ—¶ï¼‰
3. â³ æ”¶é›†è®­ç»ƒæ•°æ®ï¼ˆæŒç»­ï¼‰
4. â³ Fine-tuningå®éªŒï¼ˆ1å¤©ï¼‰

**é¢„æœŸ**: æ¥è¿‘å•†ä¸šçº§æ™ºèƒ½æ°´å¹³

---

## æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”

| æŒ‡æ ‡ | å½“å‰ (v11.2) | P0ä¼˜åŒ–å | P1ä¼˜åŒ–å | P2ç›®æ ‡ |
|------|-------------|----------|----------|--------|
| **å¹³å‡å»¶è¿Ÿ** | 3000ms | 500ms* | 2500ms | 2000ms |
| **å‡†ç¡®ç‡** | 60% | 65% | 90% | 99% |
| **çƒ­è·¯å¾„å‘½ä¸­ç‡** | 20% | 80% | 80% | 85% |
| **è¯­è¨€çº¯åº¦** | ä¸­æ—¥æ··ç”¨ | âœ…çº¯æ—¥è¯­ | âœ…çº¯æ—¥è¯­ | âœ…çº¯æ—¥è¯­ |
| **åºåˆ—ç†è§£** | âŒå¤±è´¥ | âš ï¸é¢„å®šä¹‰ | âœ…7BæˆåŠŸ | âœ…Claudeçº§ |
| **æˆæœ¬/å¤©** | $0 | $0 | $0 | $0.30 |

*P0å»¶è¿Ÿæ”¹å–„ä¸»è¦é çƒ­è·¯å¾„æ‰©å±•ï¼ˆ80%å‘½ä¸­ï¼‰ï¼Œéçƒ­è·¯å¾„ä»3ç§’

---

## é£é™©å’Œé™åˆ¶

### æŠ€æœ¯é™åˆ¶
1. **Jetsonç®—åŠ›ä¸Šé™**: Orin NXæ— æ³•è¿è¡Œ13B+æ¨¡å‹
2. **æœ¬åœ°LLMå¤©èŠ±æ¿**: Qwen 7Bç†è§£èƒ½åŠ›<Claude
3. **ç½‘ç»œä¾èµ–**: äº‘ç«¯fallbackéœ€è¦ç¨³å®šäº’è”ç½‘

### èµ„æºéœ€æ±‚
1. **å¼€å‘æ—¶é—´**: P0 (2å°æ—¶), P1 (1å¤©), P2 (3å¤©)
2. **æµ‹è¯•æ•°æ®**: éœ€è¦æ”¶é›†1000+çœŸå®å¯¹è¯æ ·æœ¬
3. **äº‘ç«¯æˆæœ¬**: P2æ–¹æ¡ˆæ¯æœˆ~$10 APIè´¹ç”¨

### å»ºè®®
- **ç«‹å³æ‰§è¡ŒP0**: å¿«é€Ÿæ”¹å–„ç”¨æˆ·ä½“éªŒ
- **æœ¬å‘¨å®ŒæˆP1**: è¾¾åˆ°å¯æ¥å—çš„æ™ºèƒ½æ°´å¹³
- **P2æŒ‰éœ€**: å¦‚æœP1æ»¡è¶³éœ€æ±‚ï¼ŒP2å¯æ¨è¿Ÿ

---

**ä½œè€…**: Claude Code
**æœ€åæ›´æ–°**: 2025-11-14 18:00 UTC
